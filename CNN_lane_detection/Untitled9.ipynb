{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "id": "jEUercapIcvN",
    "outputId": "60ce0467-1018-40da-c1b5-3fabfc475312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'lane-detection-dataset'...\n",
      "remote: Enumerating objects: 486, done.\u001b[K\n",
      "remote: Counting objects: 100% (486/486), done.\u001b[K\n",
      "remote: Compressing objects: 100% (486/486), done.\u001b[K\n",
      "remote: Total 1083 (delta 0), reused 486 (delta 0), pack-reused 597\u001b[K\n",
      "Receiving objects: 100% (1083/1083), 112.90 MiB | 4.85 MiB/s, done.\n",
      "Resolving deltas: 100% (3/3), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AdityaKarn/lane-detection-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6Du6_U4AIni6",
    "outputId": "4f9c9352-f833-4b1f-c433-5e30e65239ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/lane-detection-dataset\n"
     ]
    }
   ],
   "source": [
    "%cd lane-detection-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "szoTrhXsIuSL",
    "outputId": "dd5d1183-ae08-44cc-dc41-38faaa9f4a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting noise\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/29/bb830ee6d934311e17a7a4fa1368faf3e73fbb09c0d80fc44e41828df177/noise-1.2.2.tar.gz (125kB)\n",
      "\r",
      "\u001b[K     |██▋                             | 10kB 20.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 20kB 5.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 30kB 6.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 40kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 51kB 6.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 61kB 7.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 71kB 7.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 81kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 92kB 7.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 102kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 112kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 122kB 7.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 133kB 7.9MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: noise\n",
      "  Building wheel for noise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for noise: filename=noise-1.2.2-cp36-cp36m-linux_x86_64.whl size=62462 sha256=10cdd132bbbe1d7f71f65c8e4a3a82a9ee59a0b5dd08effecb459659d2fc9d9f\n",
      "  Stored in directory: /root/.cache/pip/wheels/fd/a3/c1/d36defe6e9f074b25dc0f018eb9f8fdd675a7ef87071ce3821\n",
      "Successfully built noise\n",
      "Installing collected packages: noise\n",
      "Successfully installed noise-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OFBdZx6RJjc0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import random\n",
    "import copy \n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from image_alteration_v2 import default_alter, draw_points\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "b-KPKqvfJnRj"
   },
   "outputs": [],
   "source": [
    "WIDTH = 240\n",
    "HEIGHT = 135\n",
    "crop = int(HEIGHT * 0.259525)\n",
    "cropped_height = HEIGHT - crop\n",
    "labels_path = 'labels/'\n",
    "val_labels_path = 'val_labels/'\n",
    "\n",
    "\n",
    "labels_pahts = os.listdir(labels_path)\n",
    "val_labels_paths = os.listdir(val_labels_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hlGwZi3iJtRR"
   },
   "outputs": [],
   "source": [
    "def img_crop(img, rl, ll):  \n",
    "    img = img[crop:,:,:]\n",
    "    rl = np.asarray(rl)\n",
    "    ll = np.asarray(ll)\n",
    "    rl[:, 1] -= crop\n",
    "    ll[:, 1] -= crop\n",
    "    return img, rl, ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "n1sZoP1hJu33"
   },
   "outputs": [],
   "source": [
    "def img_preprocess(img, right_lane, left_lane):\n",
    "    img, rl, ll = img_crop(img, right_lane, left_lane)\n",
    "    img = cv2.resize(img, (WIDTH, cropped_height))\n",
    "\n",
    "    rl_div_x = (rl[:,0]) / WIDTH\n",
    "    rl_div_y = (rl[:,1]) / cropped_height\n",
    "    rl = [rl_div_x, rl_div_y]\n",
    "    rl = np.asarray(rl)\n",
    "    rl = rl.transpose()\n",
    "\n",
    "    ll_div_x = (ll[:,0]) / WIDTH\n",
    "    ll_div_y = (ll[:,1]) / cropped_height\n",
    "    ll = [ll_div_x, ll_div_y]\n",
    "    ll = np.asarray(ll)\n",
    "    ll = ll.transpose()\n",
    "\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR)\n",
    "    img = cv2.GaussianBlur(img,  (3, 3), 0)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img/255\n",
    "    return img, rl, ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "u4ZJb-CDJwS5"
   },
   "outputs": [],
   "source": [
    "def batch_generator(labels_path, batch_size, istraining):\n",
    "    labels_pahts = os.listdir(labels_path)\n",
    "    while True:\n",
    "        batch_img = []\n",
    "        batch_points = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            label = pickle.load(open(labels_path + labels_pahts[i], \"rb\"))\n",
    "            img, rl, ll = label['img'], label['right_lane'], label['left_lane']\n",
    "\n",
    "            if istraining:\n",
    "                img, rl, ll = default_alter(img, rl, ll)\n",
    "\n",
    "\n",
    "            img, rl, ll = img_preprocess(img, rl, ll)\n",
    "            # Flatten and concat points\n",
    "            rl_ravel = np.ravel(rl)\n",
    "            ll_ravel = np.ravel(ll)\n",
    "            points = np.concatenate((rl_ravel, ll_ravel))\n",
    "            \n",
    "            batch_img.append(img)\n",
    "            points = points[:24]\n",
    "            batch_points.append(points)\n",
    "\n",
    "        batch_img = np.asarray(batch_img)\n",
    "        batch_points = np.asarray(batch_points)\n",
    "        # print(batch_points.shape)\n",
    "        yield (batch_img, batch_points)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "omiuZooPJxgf"
   },
   "outputs": [],
   "source": [
    "def detection_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(36, (5, 5), strides=(2,2), input_shape=(cropped_height,WIDTH,3), activation='relu'))\n",
    "    model.add(Conv2D(54, (5, 5), strides=(2,2), activation='relu'))\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2,2), activation='relu'))\n",
    "    model.add(Conv2D(96, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(96, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(232, activation='relu'))\n",
    "    model.add(Dense(116, activation='relu'))\n",
    "    model.add(Dense(24))\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr=1e-4, decay=0.00000010), loss = 'mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "ppy1ZRZpJ0pI",
    "outputId": "088675ba-5b75-454b-a26b-6a3b57165a82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for 8 seconds...\n",
      "TensorBoard link:\n",
      "https://94c81491a8fd.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
    "\n",
    "tbc=TensorBoardColab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "YOVZF8lGJ3Xj",
    "outputId": "c500d5d3-3e76-4eae-b752-037bd0529c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "4WcV0PM2J49a",
    "outputId": "5faecf2a-6aac-418a-a25f-13c6d4e7537a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "filepath = \"/content/gdrive/My Drive/checkpoints/epochs:{epoch:03d}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, period=100, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DnEluo5xKE6j"
   },
   "outputs": [],
   "source": [
    "model = detection_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1DVdBBhPKKMl",
    "outputId": "a4100edf-5b2c-40f8-d173-5ce12fef454b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-4be1ea5e8f12>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.1512 - val_loss: 0.0501\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0346 - val_loss: 0.0260\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0230 - val_loss: 0.0189\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0190 - val_loss: 0.0153\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0150 - val_loss: 0.0131\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0023 - val_loss: 0.0024\n"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(batch_generator(labels_path, 24, 1), \n",
    "                                        steps_per_epoch=20,\n",
    "                                        epochs=40, \n",
    "                                        validation_data=batch_generator(val_labels_path, 24, 1),\n",
    "                                        validation_steps=10, \n",
    "                                        verbose=True, \n",
    "                                        shuffle=True,\n",
    "                                        callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hGdbGRUKgnqB"
   },
   "outputs": [],
   "source": [
    "model.save(\"model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "iFPBuEtQpr5W",
    "outputId": "6be41f4b-1fd4-42b7-8a64-9f001ff0043a"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_98f34416-61b2-4f3e-8630-ca2217d40371\", \"model_1.h5\", 34483968)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('model_1.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dw6LX8fipvYQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
